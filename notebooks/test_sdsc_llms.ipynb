{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7590bb7-393b-4a36-8526-a7986a880f1e",
   "metadata": {},
   "source": [
    "# Test for SDSC LLMs\n",
    "See: https://sdsc-llm-docs.nrp.ai/\n",
    "\n",
    "Source: https://sdsc-llm-docs.nrp.ai/userdocs/api/python_basic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663ad40a-14ce-4a07-b7b2-fcda98ebb178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "llama3.1-70B: 1 + 1 = 2\n",
      "--------------------\n",
      "mixtral: The sum of 1 + 1 is 2.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variable\n",
    "ENV_PATH = \"../.env\"\n",
    "load_dotenv(ENV_PATH, override=True)\n",
    "\n",
    "API_KEY = os.environ.get(\"SDSC_LLM_API_KEY\")\n",
    "BASE_URL = os.environ.get(\"SDSC_LLM_BASE_URL\")\n",
    "\n",
    "def auth():\n",
    "    client = OpenAI(\n",
    "        api_key=API_KEY,\n",
    "        base_url=BASE_URL\n",
    "    )\n",
    "\n",
    "    return client\n",
    "\n",
    "def test_model_list(client: OpenAI):\n",
    "    models = client.models.list()\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Note that in messages, only the \"user\" role is included. \n",
    "This is to maximize compatibility, since models like danube2 are not compatible with \"system\" role.\n",
    "\"\"\"\n",
    "def test_completions_model(client: OpenAI, model: str):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Solve 1 + 1\",\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    return chat_completion\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = auth()\n",
    "    test_models_list = test_model_list(client)\n",
    "    print(\"-\" * 20)\n",
    "    llama3_test_completion = test_completions_model(client, \"meta-llama/Meta-Llama-3.1-70B-Instruct\")\n",
    "    mixtral_test_completion = test_completions_model(client, \"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "\n",
    "    print(\"llama3.1-70B: \" + llama3_test_completion.choices[0].message.content.strip())\n",
    "    print(\"-\" * 20)\n",
    "    print(\"mixtral: \" + mixtral_test_completion.choices[0].message.content.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
