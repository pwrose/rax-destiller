{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2ad46e",
   "metadata": {},
   "source": [
    "# Summarize an article from PubMedCentral (PMC)\n",
    "This notebook retrieves a pdf file of an article from PMC and extracts key information for the RADx-rad project.\n",
    "\n",
    "It can use either the public OpenAI API or the interal SDSC LLM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c29422d-38d9-4447-b26d-e322888a07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the PMC Id of the article (note, not all articles have an associated pdf file)\n",
    "\n",
    "# pmcid = \"PMC10190252\"\n",
    "# pmcid = \"PMC10463275\"\n",
    "pmcid = \"PMC8402658\"\n",
    "# pmcid = \"PMC840265\" # this example is a test for an invalid PMC ID\n",
    "# pmcid = \"PMC8854333\"\n",
    "# pmcid = \"PMC9386735\"\n",
    "# pmcid = \"PMC9725778\"\n",
    "\n",
    "# The following articles cause a timeout error:\n",
    "#    InternalServerError: <html><body><h1>504 Gateway Time-out</h1>\n",
    "#    The server didn't respond in time.\n",
    "# pmcid = \"PMC10121104\"\n",
    "# pmcid = \"PMC7954844\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ae841c-4fc9-4161-bd35-6efc2e14e326",
   "metadata": {},
   "source": [
    "## Prompts to extract summarize the RADx-rad articles\n",
    "Modify to your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d145619-956c-425f-98a6-52799c4870c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "Your are a researcher working on COVID diagnostic and surveillance methods. You job is to summarize the content of an article. \n",
    "Ignore the \"References\" and \"Acknowledgment\" sections. Evaluate the article using the following aspects: \n",
    "Objective and Scope, Methodology, Biorecognition Elements, Key Findings, Limitations, Potential Applications, and Study Type. \n",
    "\"\"\"\n",
    "\n",
    "assistant_message = \"\"\"\n",
    "Present the result in JSON format as in the example below without additional text output. Include the pmcid, which is the first word in the input. \n",
    "The sub-critera in the example below are just a guide. Add or remove sub-criteria for each aspect based on the content. \n",
    "For the Study Type, answer with yes or no. If none of the Study Types apply, use the \"Other\" sub-category and describe the study.\n",
    "\n",
    "Example:\n",
    "{\n",
    "{\"Article\":<pmcid>,\n",
    "\"Title\":<title>,\n",
    "\"Objective and Scope\": {\n",
    "  \"Objective\":<text>,\n",
    "  \"Scope\":<text>\n",
    "},\n",
    "\"Methodology\": {\n",
    "  \"Design\":<text>,\n",
    "  \"Testing\":<text>,\n",
    "  \"Validation\":<text>\n",
    "  <other sub-criteria as needed>:<text>\n",
    "},\n",
    "\"Key Findings\": {\n",
    "  \"Sensitivity\":<text>,\n",
    "  \"Specificity\":<text>,\n",
    "  \"Limit of Detection (LOD)\":<text>\n",
    "  \"Variant detection\":<text>\n",
    "  \"Cross-reactivity with other viruses\":<text>\n",
    "   <other sub-criteria as needed>:<text>\n",
    "},\n",
    "\"Limitations\": {\n",
    "  \"Testing\": <text>,\n",
    "  \"Environmental Factors\":<text>\n",
    "   <other sub-criteria as needed>:<text>\n",
    "},\n",
    "\"Potential Applications\": {\n",
    "  \"Point-of-Care Testing\":<text>,\n",
    "  \"Non-Invasive Diagnostics\":<text>\"\n",
    "   <other sub-criteria as needed>:<text>\n",
    "}\n",
    "\"Study Type\": {\n",
    "  \"Diagnostic Method Development\": yes or no,\n",
    "  \"Wastewater Surveillance\": yes or no,\n",
    "  \"COVID or SARS-CoV-2 related\": yes or no\n",
    "  \"other\":<specify other types of study as text>\n",
    "}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8c18f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5592dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc49daf2-581b-4706-8d2e-c714785c3927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "# API keys and other configuration parameters are stored in the .env file.\n",
    "# To create the .env file, copy the env_template file to .env and set your API keys.\n",
    "ENV_PATH = \"../.env\"\n",
    "load_dotenv(ENV_PATH, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160575a-76bc-43a7-81b7-c62975acd457",
   "metadata": {},
   "source": [
    "## Set up API key and create client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b819b4-bb09-419a-8d28-72c5b182afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a service\n",
    "# service = \"OPENAI\" \n",
    "service = \"SDSC_LLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c065b96d-3824-44a3-bbc4-634c5e2a4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if service == \"OPENAI\":\n",
    "    # https://platform.openai.com/docs/models\n",
    "    MODEL = os.environ.get(\"OPENAI_MODEL\")\n",
    "    API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "if service == \"SDSC_LLM\":\n",
    "    # https://ai.meta.com/blog/meta-llama-3/\n",
    "    MODEL = os.environ.get(\"SDSC_LLM_MODEL\")\n",
    "    API_KEY = os.environ.get(\"SDSC_LLM_API_KEY\")\n",
    "    BASE_URL = os.environ.get(\"SDSC_LLM_BASE_URL\")\n",
    "    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3918dfe-8093-4e78-927b-4b3ff17d4931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meta-llama/Meta-Llama-3.1-70B-Instruct']\n"
     ]
    }
   ],
   "source": [
    "# Available models\n",
    "models = utils.get_available_models(client)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f05584-64f5-4592-bf1b-d83d7da95c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default model: meta-llama/Meta-Llama-3.1-70B-Instruct\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using the default model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba81733-9bab-4f8e-84f0-b19a4d028914",
   "metadata": {},
   "source": [
    "## Download article from PMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb275adf-d239-4cf6-9d52-807323e2b240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters:   62651\n",
      "Number of tokens (GTP): 15898\n",
      "Cost for input tokens:  0.0 $US\n"
     ]
    }
   ],
   "source": [
    "text = utils.load_pdf_from_pmc(pmcid)\n",
    "\n",
    "# Prepend PMC Id\n",
    "text = pmcid + \":\" + text\n",
    "\n",
    "# Print input metrics\n",
    "num_tokens = utils.get_token_count(text, MODEL)\n",
    "print(f\"Number of characters:   {len(text)}\")\n",
    "print(f\"Number of tokens (GTP): {num_tokens}\")\n",
    "print(f\"Cost for input tokens:  {utils.get_token_cost(num_tokens, MODEL)} $US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ae22c-92bb-42a5-8735-ff7945f33dbf",
   "metadata": {},
   "source": [
    "## Create the summary in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8bb1bc-e97b-46a9-a876-d355156e7a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"Article\": \"PMC8402658\",\n",
      "\"Title\": \"Monitoring SARS-CoV-2 Populations in Wastewater by Amplicon Sequencing and Using the Novel Program SAM Reﬁner\",\n",
      "\"Objective and Scope\": {\n",
      "  \"Objective\": \"To develop a computational workflow for monitoring SARS-CoV-2 populations in wastewater using amplicon sequencing and a novel program called SAM Reﬁner\",\n",
      "  \"Scope\": \"The study focuses on the development of a method for tracking SARS-CoV-2 variants in wastewater using amplicon sequencing and SAM Reﬁner, with a specific focus on the spike gene\"\n",
      "},\n",
      "\"Methodology\": {\n",
      "  \"Design\": \"The study used a combination of amplicon sequencing and computational analysis to track SARS-CoV-2 variants in wastewater\",\n",
      "  \"Testing\": \"The method was tested on wastewater samples from a Missouri sewershed\",\n",
      "  \"Validation\": \"The results were validated by comparing the outputs of SAM Reﬁner with known variant lineages and polymorphisms\"\n",
      "},\n",
      "\"Biorecognition Elements\": {\n",
      "  \"Target\": \"SARS-CoV-2 spike gene\",\n",
      "  \"Primers\": \"Loci-speciﬁc primers were used to target 3 regions of the spike gene: N-terminal domain (NTD), receptor binding domain (RBD), and the region of the S1 and S2 subunit split (S1S2)\"\n",
      "},\n",
      "\"Key Findings\": {\n",
      "  \"Sensitivity\": \"The method was able to detect SARS-CoV-2 variants in wastewater with high sensitivity\",\n",
      "  \"Specificity\": \"The method was able to specifically identify known variant lineages and polymorphisms\",\n",
      "  \"Limit of Detection (LOD)\": \"Not reported\",\n",
      "  \"Variant detection\": \"The method was able to detect the emergence of two variants of concern, B.1.1.7 (Alpha) and P.1 (Gamma), and their displacement of the D614G B.1 variant in a Missouri sewershed\"\n",
      "},\n",
      "\"Limitations\": {\n",
      "  \"Testing\": \"The method requires specialized equipment and expertise in computational analysis\",\n",
      "  \"Environmental Factors\": \"The method may be affected by environmental factors such as wastewater treatment processes and sample handling\"\n",
      "},\n",
      "\"Potential Applications\": {\n",
      "  \"Point-of-Care Testing\": \"The method has potential applications in point-of-care testing for SARS-CoV-2 variants\",\n",
      "  \"Non-Invasive Diagnostics\": \"The method is non-invasive and can be used for diagnostics in wastewater treatment plants\"\n",
      "},\n",
      "\"Study Type\": {\n",
      "  \"Diagnostic Method Development\": \"yes\",\n",
      "  \"Wastewater Surveillance\": \"yes\",\n",
      "  \"COVID or SARS-CoV-2 related\": \"yes\",\n",
      "  \"Other\": \"no\"\n",
      "}\n",
      "}\n",
      "\n",
      "CPU times: user 29.1 ms, sys: 4.56 ms, total: 33.7 ms\n",
      "Wall time: 47.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = utils.prompt_gpt(client, MODEL, text, system_message, assistant_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34665e0a-8e49-4d14-847f-940694bb11c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
